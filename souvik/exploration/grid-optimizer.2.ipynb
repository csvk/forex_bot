{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "import pickle as pkl\n",
    "import plotly.graph_objects as go\n",
    "from plotting import CandlePlot\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    \n",
    "    def __init__(self, source):\n",
    "        assert type(source) == str or type(source) == pd.DataFrame, 'Invalid source'\n",
    "        if type(source) == str:\n",
    "            self.df = {\n",
    "                'raw': pd.read_pickle(source)\n",
    "            }\n",
    "        elif type(source) == pd.DataFrame:\n",
    "            self.df = {\n",
    "                'raw': source.copy()\n",
    "            }            \n",
    "\n",
    "        if 'time' in self.df['raw'].columns:\n",
    "            self.df['raw']['time'] = [ x.replace(tzinfo=None) for x in self.df['raw']['time']]\n",
    "        self.datalen = self.df['raw'].shape[0]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        repr = str()\n",
    "        for name, df in self.df.items():\n",
    "            repr = repr + name + ':\\n' + str(pd.concat([df.head(2), df.tail(1)])) + '\\n'\n",
    "        return repr\n",
    "\n",
    "    def prep_data(self, name: str, start: int, end: int, source: str='raw', cols: list=None):\n",
    "        '''Create new dataframe with specified list of columns and number of rows as preparation for fast data creation\n",
    "        '''\n",
    "        # assert (direction != 1 or direction != -1), 'direction must be 1 (top) or -1 (bottom)'\n",
    "\n",
    "        if cols == None:\n",
    "            cols = self.df[source].columns\n",
    "        # if direction == 1:\n",
    "        #     self.df[name] = self.df[source][cols].iloc[:rows].copy()\n",
    "        # else:\n",
    "        #     self.df[name] = self.df[source][cols].iloc[-rows:].copy()\n",
    "        if start == None:\n",
    "            start = 0\n",
    "        if end == None:\n",
    "            end = self.datalen\n",
    "\n",
    "        assert end > start, f'start={start}, end={end} not valid'\n",
    "\n",
    "        self.df[name] = self.df[source][cols].iloc[start:end].copy()\n",
    "        self.df[name].reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def add_columns(self, name: str, cols: dict):\n",
    "        '''Add new columns to component dataframes\n",
    "        '''        \n",
    "        exist_cols = list(self.df[name].columns)\n",
    "        # cols = exist_cols + cols\n",
    "        for col, _type in cols.items():\n",
    "            self.df[name][col] = pd.Series(dtype=_type) #self.df[name][col].apply(_type)\n",
    "        # self.df[name] = self.df[name].reindex(columns = cols) \n",
    "\n",
    "    def prepare_fast_data(self, name: str, start: int, end: int, source: str='raw', cols: list=None, add_cols: dict=None):\n",
    "        '''Prepare data as an array for fast processing\n",
    "        fcols = {col1: col1_index, col2: col2_index, .... }     \n",
    "        fastdf = [array[col1], array[col2], array[col3], .... ]\n",
    "        Accessed by: self.fdata()\n",
    "        '''\n",
    "\n",
    "        self.prep_data(name=name, start=start, end=end, source=source, cols=cols)\n",
    "        if add_cols:\n",
    "            # types = dict() if types is None else types\n",
    "            self.add_columns(name=name, cols=add_cols)\n",
    "\n",
    "        self.fcols = dict()\n",
    "        for i in range(len(self.df[name].columns)):\n",
    "            self.fcols[self.df[name].columns[i]] = i\n",
    "        self.fastdf = [self.df[name][col].array for col in self.df[name].columns]\n",
    "        self.fdatalen = len(self.fastdf[0])\n",
    "\n",
    "    def fdata(self, column: str=None, index: int=None, rows: int=None):\n",
    "        if column is None:\n",
    "            return self.fastdf\n",
    "        if index is None:\n",
    "            return self.fastdf[self.fcols[column]]\n",
    "        else:\n",
    "            if rows:\n",
    "                try:\n",
    "                    return self.fastdf[self.fcols[column]][index:index+rows]\n",
    "                except:\n",
    "                    return self.fastdf[self.fcols[column]][index:]\n",
    "            else:\n",
    "                return self.fastdf[self.fcols[column]][index]\n",
    "        \n",
    "    def update_fdata(self, column: str, index: int=None, value: float=None):\n",
    "        assert value is not None, 'Value cannot be null'\n",
    "        if index is None:\n",
    "            assert len(value) == self.fdatalen\n",
    "            for i in range(self.fdatalen):\n",
    "                self.fastdf[self.fcols[column]][i] = value[i]\n",
    "                print(i, )\n",
    "        else:\n",
    "            self.fastdf[self.fcols[column]][index] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/instruments.json\", 'r') as f:\n",
    "    instr = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'EUR_GBP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instr[ticker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(f\"../data/{ticker}_M5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['pip_return'] = (df.mid_c - df.mid_c.shift(1)) * pow(10, -instr[ticker]['pipLocation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([df.head(3), df.tail(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_cols = ['time', 'mid_o', 'mid_c', 'bid_o', 'ask_o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = Data(df[our_cols])\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE, ENTRY, TP, SL = 0, 1, 2, 3\n",
    "EXIT, PIPS = 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(ticker: str, frequency: str):\n",
    "    our_cols = ['time', 'mid_c', 'bid_c', 'ask_c']\n",
    "    df = pd.read_pickle(f\"../data/{ticker}_{frequency}.pkl\")\n",
    "    return Data(df[our_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_trades(d: Data, i: int, tp_pips: int, sl_pips: int, trade_size: int, trade_no: int):\n",
    "    long_tp = d.fdata('mid_c', i) + tp_pips * pow(10, instr[ticker]['pipLocation'])\n",
    "    short_tp = d.fdata('mid_c', i) - tp_pips * pow(10, instr[ticker]['pipLocation'])\n",
    "\n",
    "    long_sl = d.fdata('mid_c', i) - sl_pips * pow(10, instr[ticker]['pipLocation'])\n",
    "    short_sl = d.fdata('mid_c', i) + sl_pips * pow(10, instr[ticker]['pipLocation'])\n",
    "\n",
    "    if i == 0:\n",
    "        open_longs, open_shorts = dict(), dict()\n",
    "    else:\n",
    "        open_longs, open_shorts = d.fdata('open_longs', i-1).copy(), d.fdata('open_shorts', i-1).copy()\n",
    "        # open_longs, open_shorts = json.loads(d.fdata('open_longs', i-1)), json.loads(d.fdata('open_shorts', i-1))\n",
    "\n",
    "    open_longs[trade_no] = (trade_size, d.fdata('bid_c', i), long_tp, long_sl) # (SIZE, ENTRY, TP, SL)\n",
    "    d.update_fdata('open_longs', i, open_longs)\n",
    "    # d.update_fdata('open_longs', i, str(open_longs).replace(\"'\",'\"'))\n",
    "    open_shorts[trade_no] = (trade_size, d.fdata('ask_c', i), short_tp, short_sl) # (SIZE, ENTRY, TP, SL)\n",
    "    d.update_fdata('open_shorts', i, open_shorts)\n",
    "    # d.update_fdata('open_shorts', i, str(open_shorts).replace(\"'\",'\"'))\n",
    "\n",
    "    d.update_fdata('new_trade_no', i, trade_no)\n",
    "    \n",
    "    return long_tp, short_tp # equals next_up_grid, next_down_grid for next grid level trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_long(d: Data, i: int, trade_no: int):\n",
    "    # Remove from open longs\n",
    "    open_longs = d.fdata('open_longs', i).copy()\n",
    "    closing_long = open_longs[trade_no]\n",
    "    del open_longs[trade_no]\n",
    "    d.update_fdata('open_longs', i, open_longs)\n",
    "\n",
    "    # Append to closed longs\n",
    "    pips = (d.fdata('ask_c', i) - closing_long[ENTRY]) * pow(10, instr[ticker]['pipLocation'])\n",
    "    # if type(d.fdata('closed_longs', i)) != dict:\n",
    "    #     closed_longs = dict()\n",
    "    # else:\n",
    "    #     closed_longs = d.fdata('closed_longs', i).copy()\n",
    "    closed_longs = d.fdata('closed_longs', i).copy() if type(d.fdata('closed_longs', i)) == dict else dict()\n",
    "    closed_longs[trade_no] = (closing_long[SIZE], closing_long[ENTRY], d.fdata('ask_c', i), pips) # (SIZE, ENTRY, EXIT, PIPS)\n",
    "\n",
    "    d.update_fdata('closed_longs', i, closed_longs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_short(d: Data, i: int, trade_no: int):\n",
    "    # Remove from open shorts\n",
    "    open_shorts = d.fdata('open_shorts', i).copy()\n",
    "    closing_short = open_shorts[trade_no]\n",
    "    del open_shorts[trade_no]\n",
    "    d.update_fdata('open_shorts', i, open_shorts)\n",
    "\n",
    "    # Append to closed shorts\n",
    "    pips = (closing_short[ENTRY] - d.fdata('bid_c', i)) * pow(10, instr[ticker]['pipLocation'])\n",
    "    # if type(d.fdata('closed_shorts', i)) != dict:\n",
    "    #     closed_shorts = dict()\n",
    "    # else:\n",
    "    #     closed_shorts = d.fdata('closed_shorts', i).copy()\n",
    "    closed_shorts = d.fdata('closed_shorts', i).copy() if type(d.fdata('closed_shorts', i)) == dict else dict()\n",
    "    closed_shorts[trade_no] = (closing_short[SIZE], closing_short[ENTRY], d.fdata('bid_c', i), pips) # (SIZE, ENTRY, EXIT, PIPS)\n",
    "\n",
    "    d.update_fdata('closed_shorts', i, closed_shorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_long_position(d: Data, i: int):\n",
    "    open_longs = d.fdata('open_longs', i).copy() if type(d.fdata('open_longs', i)) == dict else dict()\n",
    "    cum_long_position = 0\n",
    "    for _, trade in open_longs.items():\n",
    "        cum_long_position = cum_long_position + trade[SIZE]\n",
    "    return cum_long_position\n",
    "\n",
    "def cum_short_position(d: Data, i: int):\n",
    "    open_shorts = d.fdata('open_shorts', i).copy() if type(d.fdata('open_shorts', i)) == dict else dict()\n",
    "    cum_short_position = 0\n",
    "    for _, trade in open_shorts.items():\n",
    "        cum_short_position = cum_short_position + trade[SIZE]\n",
    "    return cum_short_position\n",
    "\n",
    "def unrealised_pnl(d: Data, i: int):\n",
    "    open_longs = d.fdata('open_longs', i).copy() if type(d.fdata('open_longs', i)) == dict else dict()\n",
    "    open_shorts = d.fdata('open_shorts', i).copy() if type(d.fdata('open_shorts', i)) == dict else dict()\n",
    "    pnl = 0\n",
    "    for _, trade in open_longs.items():\n",
    "        pnl = pnl + trade[SIZE] * (d.fdata('mid_c', i) - trade[ENTRY])\n",
    "    for _, trade in open_shorts.items():\n",
    "        pnl = pnl + trade[SIZE] * (trade[ENTRY] - d.fdata('mid_c', i))\n",
    "    return pnl\n",
    "\n",
    "def realised_pnl(d: Data, i: int):\n",
    "    closed_longs = d.fdata('closed_longs', i).copy() if type(d.fdata('closed_longs', i)) == dict else dict()\n",
    "    closed_shorts = d.fdata('closed_shorts', i).copy() if type(d.fdata('closed_shorts', i)) == dict else dict()\n",
    "    pnl = 0\n",
    "    for _, trade in closed_longs.items():\n",
    "        pnl = pnl + trade[SIZE] * (trade[EXIT] - trade[ENTRY])\n",
    "    for _, trade in closed_shorts.items():\n",
    "        pnl = pnl + trade[SIZE] * (trade[ENTRY] - trade[EXIT])\n",
    "    return pnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_values(d, i):\n",
    "    _cum_long_position = cum_long_position(d, i)\n",
    "    _cum_short_position = cum_short_position(d, i)\n",
    "    _unrealised_pnl = unrealised_pnl(d, i)\n",
    "    _realised_pnl = realised_pnl(d, i)\n",
    "    ac_bal = d.fdata('ac_bal', i-1) + _realised_pnl\n",
    "    margin_used = (_cum_long_position + _cum_short_position) * float(instr[ticker]['marginRate'])\n",
    "    margin_closeout = ac_bal + _unrealised_pnl\n",
    "    return margin_used, margin_closeout\n",
    "\n",
    "def stop_loss_oldest(d: Data, i: int):\n",
    "    margin_used, margin_closeout = current_values(d, i)\n",
    "    # Margin call is triggered when margin closeout is less than 50% of margin used.\n",
    "    # Here stop loss is triggered if it falls below 60%\n",
    "    if margin_closeout < margin_used * 0.6:\n",
    "        reduced_margin = margin_closeout / 0.6\n",
    "        while reduced_margin < margin_used:\n",
    "            longs = list(d.fdata('open_longs', i).keys())\n",
    "            shorts = list(d.fdata('open_shorts', i).keys())\n",
    "            oldest_long = longs[0] if len(longs) > 0 else None\n",
    "            oldest_short = shorts[0] if len(shorts) > 0 else None\n",
    "            if oldest_long == None and oldest_short == None:\n",
    "                break\n",
    "            elif oldest_long == None:\n",
    "                close_short(d, i, oldest_short)\n",
    "                margin_used, _ = current_values(d, i)\n",
    "                print(f'stop loss: {i}, short: {oldest_short}')\n",
    "            elif oldest_short == None:\n",
    "                close_long(d, i, oldest_long)\n",
    "                margin_used, _ = current_values(d, i)\n",
    "                print(f'stop loss: {i}, long: {oldest_long}')\n",
    "            else:\n",
    "                if oldest_long <= oldest_short:\n",
    "                    close_long(d, i, oldest_long)\n",
    "                    margin_used, _ = current_values(d, i)\n",
    "                    print(f'stop loss: {i}, long: {oldest_long}')\n",
    "                else:\n",
    "                    close_short(d, i, oldest_short)\n",
    "                    margin_used, _ = current_values(d, i)\n",
    "                    print(f'stop loss: {i}, short: {oldest_short}')\n",
    "\n",
    "def stop_loss_farthest(d: Data, i: int):\n",
    "    margin_used, margin_closeout = current_values(d, i)\n",
    "    # Margin call is triggered when margin closeout is less than 50% of margin used.\n",
    "    # Here stop loss is triggered if it falls below 60%\n",
    "    price = d.fdata('mid_c', i)\n",
    "    if margin_closeout < margin_used * 0.6:\n",
    "        reduced_margin = margin_closeout / 0.6\n",
    "        while reduced_margin < margin_used:\n",
    "            farthest_long_price, farthest_short_price = price, price\n",
    "            farthest_long, farthest_short = None, None\n",
    "            for long, trade in d.fdata('open_longs', i).items():\n",
    "                if trade[ENTRY] > farthest_long_price:\n",
    "                    farthest_long_price = trade[ENTRY]\n",
    "                    farthest_long = long\n",
    "            for short, trade in d.fdata('open_shorts', i).items():\n",
    "                if trade[ENTRY] < farthest_short_price:\n",
    "                    farthest_short_price = trade[ENTRY]\n",
    "                    farthest_short = short\n",
    "            if farthest_long == None and farthest_short == None:\n",
    "                break\n",
    "            elif farthest_long == None:\n",
    "                close_short(d, i, farthest_short)\n",
    "                margin_used, _ = current_values(d, i)\n",
    "                print(f'stop loss: {i}, short: {farthest_short}')\n",
    "            elif farthest_short == None:\n",
    "                close_long(d, i, farthest_long)\n",
    "                margin_used, _ = current_values(d, i)\n",
    "                print(f'stop loss: {i}, long: {farthest_long}')\n",
    "            else:\n",
    "                if farthest_long_price - price > price - farthest_short_price:\n",
    "                    close_long(d, i, farthest_long)\n",
    "                    margin_used, _ = current_values(d, i)\n",
    "                    print(f'stop loss: {i}, long: {farthest_long}')\n",
    "                else:\n",
    "                    close_short(d, i, farthest_short)\n",
    "                    margin_used, _ = current_values(d, i)\n",
    "                    print(f'stop loss: {i}, short: {farthest_short}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ac_values(d: Data, i: int, init_bal: float=None):\n",
    "    d.update_fdata('cum_long_position', i, cum_long_position(d, i))\n",
    "    d.update_fdata('cum_short_position', i, cum_short_position(d, i))\n",
    "    d.update_fdata('unrealised_pnl', i, unrealised_pnl(d, i))\n",
    "    d.update_fdata('realised_pnl', i, realised_pnl(d, i))\n",
    "    # First candle\n",
    "    if i == 0:               \n",
    "        d.update_fdata('ac_bal', i, init_bal)\n",
    "    # Subsequent candles\n",
    "    else:\n",
    "        d.update_fdata('ac_bal', i, d.fdata('ac_bal', i-1) + d.fdata('realised_pnl', i))\n",
    "    d.update_fdata('margin_used', i, \\\n",
    "                (d.fdata('cum_long_position', i) + d.fdata('cum_short_position', i)) * float(instr[ticker]['marginRate']))\n",
    "    d.update_fdata('margin_closeout', i, d.fdata('ac_bal', i) + d.fdata('unrealised_pnl', i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sim(d: Data, sim_name: str, start: int, end: int, init_bal: int, init_trade_size: int, grid_pips: int, sl_grid_count: int) -> pd.DataFrame:\n",
    "    tp_pips = grid_pips\n",
    "    sl_pips = grid_pips * sl_grid_count\n",
    "    \n",
    "    add_cols = dict(\n",
    "        open_longs=object,\n",
    "        open_shorts=object,\n",
    "        new_trade_no=int,\n",
    "        closed_longs=object,\n",
    "        closed_shorts=object,\n",
    "        cum_long_position=int,\n",
    "        cum_short_position=int,\n",
    "        unrealised_pnl=float,\n",
    "        realised_pnl=float,\n",
    "        ac_bal=float,\n",
    "        margin_used=float,\n",
    "        margin_closeout=float\n",
    "    )\n",
    "    d.prepare_fast_data(name=sim_name, start=start, end=end, add_cols=add_cols)\n",
    "\n",
    "    for i in tqdm(range(d.fdatalen), desc=\" Simulating... \"):       \n",
    "        # First candle\n",
    "        if i == 0:\n",
    "            # Open trades\n",
    "            trade_no = 1            \n",
    "            next_up_grid, next_down_grid = open_trades(d=d, i=i, tp_pips=tp_pips, sl_pips=sl_pips, trade_size=init_trade_size, trade_no=trade_no)\n",
    "            calc_ac_values(d, i, init_bal)\n",
    "        # Subsequent candles\n",
    "        else:\n",
    "            # Open trades\n",
    "            if d.fdata('mid_c', i) >= next_up_grid or d.fdata('mid_c', i) <= next_down_grid:\n",
    "                trade_no = trade_no + 1            \n",
    "                next_up_grid, next_down_grid = open_trades(d=d, i=i, tp_pips=tp_pips, sl_pips=sl_pips, trade_size=init_trade_size, trade_no=trade_no)\n",
    "            else: # Cascade open positions from prev candle to current candle\n",
    "                d.update_fdata('open_longs', i, d.fdata('open_longs', i-1).copy())\n",
    "                d.update_fdata('open_shorts', i, d.fdata('open_shorts', i-1).copy())\n",
    "\n",
    "            # Take profit long positions\n",
    "            open_longs = d.fdata('open_longs', i).copy()\n",
    "            for trade_no, trade in open_longs.items():\n",
    "                if d.fdata('mid_c', i) >= trade[TP]: # or d.fdata('mid_c', i) <= trade[SL]:\n",
    "                    close_long(d, i, trade_no)\n",
    "\n",
    "            # Take profit short positions\n",
    "            open_shorts = d.fdata('open_shorts', i).copy()\n",
    "            for trade_no, trade in open_shorts.items():\n",
    "                if d.fdata('mid_c', i) <= trade[TP]: # or d.fdata('mid_c', i) >= trade[SL]:\n",
    "                    close_short(d, i, trade_no)\n",
    "\n",
    "            stop_loss_farthest(d, i)\n",
    "            calc_ac_values(d, i)\n",
    "\n",
    "    return dict(\n",
    "        sim_name = sim_name,\n",
    "        init_trade_size=init_trade_size,\n",
    "        grid_pips=grid_pips,\n",
    "        sl_grid_count=sl_grid_count,\n",
    "        results = d.df[sim_name]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sim(d: Data, ticker: str, frequency: str, counter: int, start: int, end:int, init_bal: int, init_trade_size: int, grid_pips: int, sl_grid_count: int, inputs_list: list, inputs_file: str):\n",
    "    sim_name = f'{ticker}-{frequency}-{counter}'\n",
    "    header = ['sim_name', 'init_trade_size', 'grid_pips', 'sl_grid_count', 'stoploss_pips']\n",
    "    inputs = [sim_name, init_trade_size, grid_pips, sl_grid_count, grid_pips * sl_grid_count]\n",
    "    print(tabulate([inputs], header, tablefmt='plain'))\n",
    "    result= run_sim(\n",
    "        d=d,\n",
    "        sim_name=sim_name,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        init_bal=init_bal,\n",
    "        init_trade_size=init_trade_size,\n",
    "        grid_pips=grid_pips,\n",
    "        sl_grid_count=sl_grid_count\n",
    "    )\n",
    "    # print('Saving files...')\n",
    "    with open(f'D:/Trading/ml4t-data/grid/{sim_name}.pkl', 'wb') as file:\n",
    "        pkl.dump(result, file)\n",
    "\n",
    "    inputs_list.append(inputs)\n",
    "    inputs_df = pd.DataFrame(inputs_list, columns=header)\n",
    "    inputs_df.to_pickle(f'D:/Trading/ml4t-data/grid/{ticker}-{frequency}-' + inputs_file)\n",
    "    \n",
    "    del d.df[sim_name]\n",
    "    counter =  counter + 1\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# periods = [None] # all candles\n",
    "# init_bal = [500, 1000, 2000, 5000]\n",
    "# trade_size = [10, 100, 1000, 10000]\n",
    "# grid_pips = [20, 30, 40, 50, 60, 100]\n",
    "# stoploss_lvl = [5, 10, 15, 20, 30, 50, 100, 10000]\n",
    "# INPUTS_FILE = 'inputs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 1\n",
    "counter = 1\n",
    "start = None\n",
    "end = None\n",
    "tickers = ['EUR_USD']\n",
    "frequency = ['M5']\n",
    "init_bal = [1000]\n",
    "init_trade_size = [1000]\n",
    "grid_pips = [20]\n",
    "sl_grid_count = [40]\n",
    "INPUTS_FILE = 'inputs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_list = list()\n",
    "for tk in tickers:\n",
    "    for f in frequency:\n",
    "        for ib in init_bal:\n",
    "            for t in init_trade_size:\n",
    "                for g in grid_pips:\n",
    "                    for sl in sl_grid_count:\n",
    "                        if counter >= checkpoint:\n",
    "                            d = read_data(ticker, f)\n",
    "                            inputs = process_sim(\n",
    "                                d=d,\n",
    "                                ticker=tk,\n",
    "                                frequency=f,\n",
    "                                counter=counter,\n",
    "                                start=start,\n",
    "                                end=end,\n",
    "                                init_bal=ib,\n",
    "                                init_trade_size=t,\n",
    "                                grid_pips=g,\n",
    "                                sl_grid_count=sl,\n",
    "                                inputs_list=inputs_list,\n",
    "                                inputs_file=INPUTS_FILE\n",
    "                            )  \n",
    "                        counter =  counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_pickle(f'D:/Trading/ml4t-data/grid/EUR_USD-M5-1.pkl')['results'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['net_bal'] = results['ac_bal'] + results['unrealised_pnl']\n",
    "results['cum_position'] = results['cum_long_position'] + results['cum_short_position']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[~results['realised_pnl'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = CandlePlot(results, candles=False)\n",
    "cp.show_plot(line_traces=['mid_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = CandlePlot(results, candles=False)\n",
    "cp.show_plot(line_traces=['ac_bal', 'net_bal', 'unrealised_pnl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = CandlePlot(results, candles=False)\n",
    "cp.show_plot(line_traces=['margin_used'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = CandlePlot(results, candles=False)\n",
    "cp.show_plot(line_traces=['cum_long_position', 'cum_short_position', 'cum_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['margin_used_50'] = results['margin_used'] * 0.5\n",
    "results['margin_call'] = results['margin_used_50'] > results['margin_closeout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = CandlePlot(results, candles=False)\n",
    "cp.show_plot(line_traces=['margin_call'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = CandlePlot(results, candles=False)\n",
    "cp.show_plot(line_traces=['margin_used_50', 'margin_closeout'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
